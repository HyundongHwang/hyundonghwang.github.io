---
layout: post
title: "251005 STREAM 이슈1. 스마트폰 만으로 촬영과 댄스점수평가를 동시에"
comments: true
tags: [STREAM, Unity, AI, 포즈추출, 실시간처리, 댄스평가, MediaPipe, KPOP, 댄스, OpenPose, 컴퓨터비전, 머신러닝, 모션분석, 패턴매칭, 실시간AI, 멀티스레드, 성능최적화, 모바일AI, 스마트폰, 비디오분석, 포즈인식, 댄스학습, 음악분석, 비트분석, 동작인식, 자세교정, 스코어링시스템]
---

# 데모 영상

먼저 데모 영상을 보시지요.

## iPad에서 연습, 평가, 결과 공유

<div class="video-container">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/Kl-6zegfLC8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>

## 금메달 받은 `르세라핌 - PerfectNight` 연습영상 유투브 개인채널 공유

<div class="video-container">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/J2wbMMzB6U8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>

## 금메달 받은 `투어스 - 첫만남은 계획대로 되지 않아` 연습영상 유투브 개인채널 공유

<div class="video-container">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/C94bOfy3t8k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>

STREAM을 하기전엔 주로 차에서 운전하면서 오디오로만 듣고 팬심을 키우다가, 이렇게 당당하게 댄스연습도 할수 있게되어 너무 영광이고 즐거웠습니다.
물론 개발은 바쁘고, 350개 넘는 클래스들의 규격과 패턴이 일정해 지면서, 이렇게 초반처럼 개발과 댄스연습을 함께 할수 있는 필요도 없어지고, 여유는 더 없어 졌습니다.
정말 바빠서 2년간 하루중에 10분이상 시간이 날것 같은 상황이면 무조건 맥북 앞에 앉았습니다.
가끔은 넷플릭스 유투브 좀 보면서 쉬고 싶었지만, 개발은 농사와 같아서, 매일 가서 눈으로 보면 고칠게 있고, 고치면 좋아지는데, 개발자가 자기사업을 하니깐 그냥 24시간 이 생각만 하게 되서 좋기도 하고 나쁜것 같기도 합니다.
오히려 8살인 저희 아들이 저보다 열심히 연습을 했습니다.
저희 아들이 보고한 버그도 꽤 됩니다.
작년4월 출시하고, 몇달간은 저희 아들이 STREAM에 깊이 빠져서 계속 춤추고, 영상 돌려보고, 급기야 와이프가 하루 사용제한 까지 거는 지경에 이르렀습니다.
이때는 그래서 서비스가 무지 잘될줄 알았으나,,, 이 기능도 익숙해 지고, 질리게 되었는지 아들도 잘 찾지 않게 되었습니다.
그리고 이때쯤 이것저것 새로운 기능을 계속 출시 했으나, 생각만큼 유저님들의 반응이 없다보니 비지니스는 정체되긴 했습니다.
비지니스는 제가 잘 모르는 분야지만 언제 따로 포스트로 얘기할 수 있는 기회가 있을것 같습니다.

<br/>
<br/>
<br/>

# 춤? 춤을 잘춘다는 것?

제가 감히 `춤이 무엇이다, 춤을 잘춘다는것은 이것이다.` 라고 얘기해도 될까요?
저는 이 사업전엔 댄스 아카데미, 댄스 연습실을 가본적이 없습니다.
20대때도 골수 공대생에 내향적인 아웃사이더라서 클럽도 못가봤습니다.
30대때 회사 회식을 대표님이 개인소유하신 클럽에서 한적이 있었는데, 도저히 너무 어색해서, 눈치보다가 화장실 가는척 하고 택시잡아타고 언른 귀가 했습니다.
참고로 KPOP 댄스를 배울수 있는 댄스 아카데미, 댄스 연습실은 우리 주위에 엄청 많이 있고 KPOP댄스 차제는 매우 대중화된 취미 입니다.
심지어 네이버지도 검색해 보면 골프존보다 많이 검색 됩니다.
아무튼 저는 `춤이 무엇이다, 춤을 잘춘다는것은 이것이다.` 라는 것을 확실히 안다고 얘기할 수 있습니다.
왜냐면, STREAM에는 댄스영상의 정확도 평가기능이 있고, 이 내부의 로직을 개발했기 때문에 잘 알고 있다고 할 수 있습니다.
약간 질문을 바꿔서 누군가에게 보컬, 피아노 연주, 기타 연주를 듣고 평가를 해 달라면 대개 좀더 쉽게 평가할 수 있다고 할 것입니다.
차이는 뭘까요?
보컬, 피아노, 기타 에는 좀더 인식하기 쉬운 패턴이 존재하고, 이 패턴이 소수로 축약되고 각 패턴들은 청자의 심리패턴과 직결되게 구성되어 있어서 그렇습니다.
예를 들면, 쉴때 듣는 잔잔한 음악, 운전할때 듣는 경쾌한 음악 이런것들이 갖는 패턴이 서로 다를 것은 듣자마자 파악할 수 있고, 만일 예상과 다른 패턴이 등장하면 이는 심리패턴과 연결되서 직감적으로 인지 할 수 있게 됩니다.
어딘가 과학 유투브 채널에서 본 내용인데, 오디오 주파수의 패턴 조합, 즉 화음이 연결된 심리상태 매핑 데이타는 인류가 자연선택설로 진화하면서 DNA에 새겨진 데이타라고 합니다. 
이는 시계열로 오디오를 분석할때는 직관적으로 알기 어렵지만, 보통 주파수 분석을 하면 화성학에 맞는 거의 정확한 패턴을 확인할 수 있고, 이것으로 새로운 음악이라도 품질을 판단할 수 있는 근거가 됩니다.
춤이 더 어려워 보이는 이유는, 시계열에서 오디오보다 훨씬 복잡한 입력차원이 존재한다고 생각해서 그렇습니다.
그렇지 않습니다.
춤이 더 패턴 분석하기 쉽습니다. 
시계열에서 발생하는 데이타 간격이 더 넓고, 모든 데이타를 따질 필요가 없이, 90% 정도 데이타는 필터아웃해도 됩니다.
또한 각 데이타에서 발생하는 차원이 오디오 처럼 1차원은 아니지만 이미지의 3차원(W, H, color)을 모두 쓰지 않고 특이점을 정할수 있습니다.
한 스텝이 펼쳐지는 짧은 순간에 한 특이점에서 다른 특이점으로 상태가 전이할때는 관절과 운동범위의 제약으로 정해진 루트이외엔 불가한 상태라 연산에서 제외할 수 있습니다. 
즉 컴퓨터로 분석하기엔 더 적은 입력데이타로 발생한 패턴을 분석하게 되니 부담이 더 적고 쉬운문제가 됩니다.
그래서 보컬, 피아노, 기타등 오디오 패턴을 분석하는 할때는 주파수 기반 분석을 하는 것이 효율적이고, 춤의 이미지 패턴 분석 할때는 시계열 기반 분석을 하는 것이 효율적입니다.
조금더 정확하게 보자면, GT(=댄서님 클래스 영상)가 있고, 이를 추종하는 영상(=내 연습영상)이 존재하고, 이를 시계열에서 대부분 필터아웃하고, 특이점을 찾아서 상태전이가 잘 되는지 그 유사도를 측정하는 식으로 알고리즘을 개발해 나갈수 있습니다.
여기에 KPOP이란 제약사항으로 좀더 최적화 할 수 있습니다.
KPOP은 보통 4/4박자, 평균 120bpm 로 볼수 있습니다.
120bpm이란 1분에 120개의 비트가 발생한다는 뜻으로(=저도 첨엔 몰랐습니다.ㅎ) 0.5초에 한번씩 비트가 발생하고, 이 리듬에 맞춰서 몸을 움직이게 됩니다.
즉 비트사운드가 발생할때 어떤 동작이 되기로 약속이 된것, 마치 리듬액션 게임처럼 정해진 순간에 정해진 동작을 해야 하는 단순한? 게임규칙을 갖고 있습니다.
물론 평가 규칙이 단순한 것이지 익히는게 쉽다고는 안했습니다.
이 약속된 동작이 다시 다차원이니깐, 즉 양팔, 양다리, 스텝, 몸통, 허리, 어깨 이런 주요포지션을 한번에 기억했다가 비트사운드 터질때마다 계속 바꿔줘야 하니 아무래도 어렵습니다.
차원의 문제로 뭐가 어렵냐고 한다면, 댄스가 가장 어렵고, 그 다음이 기악, 그리고 어쨋든 오디오 level 한개만 갖는 보컬이 쉽다고 하겠습니다.
즉 춤을 잘추고 싶으면, 머리가 좋아야 합니다.
몸치는 정확히 몸이 안좋은게 아니라 머리가 안좋은 것입니다.
물론 많은 연습으로 운동을 기억하는 소뇌가 패턴을 외우게 되었는데, 그 패턴이 자꾸 반복되면, 캐시 입출력이 되니깐 상당한 도움이 될거라 생각합니다.

<br/>
<br/>
<br/>

# 댄스 클래스 에셋 준비

## 댄스 클래스 영상 촬영
가장 먼저 전문 댄서님 즉 이 클래스의 선생님이 아주 정확하게 각 댄스 컨텐츠 별로 기준이 될 GT(=GroundTruth) 영상을 만들어 주셔야 합니다.
저같은 일반인은 감히 상상도 할 수 없지만, 우리 선생님들은 며칠전에만 알려드리면 혼자서 4곡의 안무를 외워오실수 있습니다.
한곡당 조금만 연습해 보면 구간이 30초 정도로 짧은 경우는 금방 외우실수 있다고 합니다.
이렇게 댄서님들이 먼저 준비가 되시면 저희 대표님 기획자Z가 촬영장비를 메고 댄스 스튜디오로 촬영을 해서 오시고, 밤새 CapCut으로 편집을 하고, 모바일에 맞는 프로필과 각종 에셋들을 CMS에 수기 입력을 하십니다.
그걸 심지어 350회를 넘게 했습니다.
쉬지 않고 개발한다고 앓는 소리 할게 아닙니다.
저희 댄서님은 두분으로 각각 4곡씩 연습해 오시면, 한번 촬영에 최대 8곡 커버가 가능합니다.
클래스 영상과 에셋을 준비하는 과정을 좀더 자세히 보면, 기본적인 영상 편집과정이 종료되면, 오디오 트랙을 촬영영상에서 뜯어내고 원음을 오프셋 맞춰서 추가합니다.
이렇게 해서 깨끗한 원음만 포함된 클래스 GT 영상을 제작할 수 있습니다.

## 오디오 분석
그 다음은 평가기준점을 만들기 위해 오디오 분석을 합니다.
이는 물론 AI에 의존하여 자동으로도 할 수 있지만, 고품질을 위해 귀로 듣고 비트를 찾아 타임스템프에 마킹하는 방식으로 수작업으로 합니다.

## 용어정리 

- 비트
  - KPOP 음악은 보통 타악기 즉 대개 드럼의 심벌로 비트를 구분하는게 일반적입니다.
  - KPOP 공연무대에 밴드의 드러머가 함께 있진 않지만, 음원에서 거의 대개 밴드의 드럼소리가 있습니다. 
  - 그 쿵쿵쿵쿵 하는 그 소리를 비트라고 합니다.
- 스텝
  - 비트와 비트간의 구간을 스텝이라고 합니다.
- 파트
  - 4/4 박자 기준 8개의 스텝이 한개의 파트를 구성합니다.
  - 파트는 댄스를 배우는 단위 기준이 되기도 합니다.
  - 댄스학원에 등록해서 배우거나, 혹은 TV예능등 댄스 배우는 장면에 자주 등장하는 `원 앤 투 앤 쓰리 앤 포 앤` 이 8개의 소리입니다.
  - STREAM 클래스 컨텐츠는 보통 30초 정도의 구간을 커버하고, 4 ~ 6 파트로 나눌수 있고, 실제 수업처럼 파트별로 배우는 기능이 제공됩니다.  

## OpenPose 분석
GT 영상을 컨텐츠 제작 서버에서 선작업을 통해 AI비전모델을 이용하여 모든 프레임을 대상으로 OpenPose의 시퀀스를 산출합니다.

<img src="https://i.imgur.com/Nte7g68.png" width="500"/>

![]()

## 댄스 클래스 에셋 준비 완료, 배포
이렇게 제작된 영상들과 오디오 분석되고 OpenPose로 분석된 메타정보들은 파일서버(=CloudFront)에 준비되어 있다가, 유저의 단말로 배포 됩니다.

<br/>
<br/>
<br/>

# 실시간 평가 로직 튜닝

이렇게 스텝/파트구분, OpenPose로 GT영상의 기준 확보를 하고 나면, 역시 유저영상에서 매칭되는 스텝/파트 지점들에서 OpenPose를 구할 수 있습니다.
이렇게 근거 데이타를 놓고 상호간 패턴매칭을 할때 쉽게 생각할 수 있는 몇가지 포인트들이 생길수 있습니다.
- 팔꿈치, 어깨, 허리, 무릅 x 좌우 = 8각
- 팔꿈치, 손, 무릅, 발 x 좌우 = 8좌표
다른 각들이나 좌표들도 산출할 수 있으나, 의미가 적거나, 변화가 적습니다.
예를들어 머리와 어깨의 각으로 동작에 의미가 생기는 경우가 별로 없고, 어깨의 좌표, 허리의 좌표 역시 동작에서 변별의 의미가 적게 생깁니다.
물론 목만 움직이는 동작이나, 허리만 튕기는 동작 같은게 전혀 없지는 않지만, 전체적인 실시간 스코어의 측정에선 큰동작이 위주가 됩니다.
이후 8각을 0~1 사이로 정규화하고, 8좌표는 몸중앙에서 부터 상대값을 사용하면서, 원좌표계로 변환후 역시 0~1 사이로 정규화 합니다.
이렇게 패턴매칭을 위해 소수의 입력으로 압축하고, 연산량 자체도 스텝포인트 단위로 집중해서 또한번 최적화 할 수 있습니다.
이후 실제로 변별력을 위해 점수가 대략 40~100점 사이로 고르게 펼쳐질수 있게 후처리 연산을 추가합니다.

## 평가 로직 상세 결과
- 이 결과를 계속 확인하면서 전체적인 스코어 경향을 파악합니다.
- ![](https://i.imgur.com/flqhhNw.png)

## 평가 로직 프레임 단위 측정도구
- 프레임단위의 평가오차를 눈으로 확인하기 위한 튜닝, 디버깅 도구.
<div class="video-container">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/KbUeO6bEQhA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>

<br/>
<br/>
<br/>

# 실시간 평가

스트림 `AI평가` 기능이 시작되면 실시간으로 실행되는 무거운 기능들이 많아집니다.
- 클래스 영상 플레이
- 카메라 프리뷰
- 클래스 오버레이 영상 플레이
- 카메라 영상 OpenPose 측정
- 댄스 스코어 측정
- 카메라 영상 녹화

이 기능들을 모바일 단말에서 실시간으로 실행해야 하기 때문에, 성능측면에서 도전적인 기능이며, 
gstreamer와 유사한 구조를 갖는 필터그래프를 만들어서 멀티스레드를 적극 활용해서 해결했습니다.

<img src="https://i.imgur.com/vHdox6k.png" width="800"/>

<br/>
<br/>
<br/>

# 마무리 

이슈1부터 글쓰기가 오래 걸리네요.
생각한게 너무 많아서 그런가... 잘 표현이 안되네요.
다행이 이슈2부터는 각각 더 작은단위라 좀 더 나을것 같습니다.
아직 서비스중인 코드라 전부 공개하기 어려운 점도 있고, 대략 1.5년 만에 기술 내용을 다시 꺼내서 글로 옮길려니, 첨부자료도 부실한것 같습니다.
부족한 부분은 댓글로 질문을 주신다면 친절히 답변드릴수 있겠습니다.

<br/>
<br/>
<br/>

# 멀티모달 LLM 활용 정확도 개선
이건 아직 서비스에 구현하지 못한 내용입니다.
현재는 정량적인 숫자 스코어로만 정확도가 표시되고 있는데, `팔을 더 뻗어 주세요.`, `동작을 더 크게 해 주세요.` 등 정성적인 피드백을 구현한다면 어떻게 할까 해서 생각해본 아이디어 입니다.
현재의 멀티모달 LLM이면 이를 실현할 수 있을것으로 생각되며, 이 피드백의 품질도 꽤 괞찮을것 같습니다.
그렇지만, 실시간 피드백은 될수 없을 것이고, 특히 이게 가장중요한데, 스트림 서비스를 운영해 보니 전체 서비스의 가치에서 이 스코어의 품질과 변별력이 엄청 중요하지는 않다는 것을 알게 되었습니다.
스트림에서 댄스의 실시간 스코어는 노래방기기의 점수와 비슷한 면이 있는데, 마찬가지로 스코어 평가와 피드백의 액션 자체의 가치보다는 쾌적한 연습의 가치가 더 중요하기 때문인것으로 생각됩니다.
그렇지만, 어찌 보면 스트림이 아닌 다른 서비스 기능이면 예를들면 요가 필라테스 동작, 태권도 동작, 근골격 자세 교정치료 등 다른 활용은 있을 것 같습니다.
[자세한 내용은 클로드와 대화했던 내용을 첨부](https://claude.ai/share/102d0b16-16b2-45f2-bb27-6a91206d94c0) 합니다.